{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ef6faa8c-6f39-4ce2-949f-bf866df3075f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Analizando la evaluación Lazy de Spark\n",
    "\n",
    "El objetivo de esta libreta es analizar y comprender la evaluación Lazy que realiza Spark. A través de algunos escenarios revisaremos en qué consiste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "350205b4-84e8-4451-ab06-5d7534db873c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Creado dataFrame\n",
    "df_fifa = spark.read.csv('/FileStore/tables/players_20.csv', header = True, inferSchema = True)\n",
    "\n",
    "df_fifa = df_fifa.select('short_name','age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a2b356d4-1723-4105-92bc-995a6bfd2e6a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+-----------------+---+\n",
       "|       short_name|age|\n",
       "+-----------------+---+\n",
       "|         L. Messi| 32|\n",
       "|Cristiano Ronaldo| 34|\n",
       "|        Neymar Jr| 27|\n",
       "|         J. Oblak| 26|\n",
       "|        E. Hazard| 28|\n",
       "+-----------------+---+\n",
       "only showing top 5 rows\n",
       "\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "+-----------------+---+\n|       short_name|age|\n+-----------------+---+\n|         L. Messi| 32|\n|Cristiano Ronaldo| 34|\n|        Neymar Jr| 27|\n|         J. Oblak| 26|\n|        E. Hazard| 28|\n+-----------------+---+\nonly showing top 5 rows\n\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_fifa.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c4bd408b-37d8-4390-9d20-2627f7e7d22f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+-----------------+---+----------+\n",
       "|       short_name|age|edad_meses|\n",
       "+-----------------+---+----------+\n",
       "|         L. Messi| 32|       384|\n",
       "|Cristiano Ronaldo| 34|       408|\n",
       "|        Neymar Jr| 27|       324|\n",
       "|         J. Oblak| 26|       312|\n",
       "|        E. Hazard| 28|       336|\n",
       "+-----------------+---+----------+\n",
       "only showing top 5 rows\n",
       "\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "+-----------------+---+----------+\n|       short_name|age|edad_meses|\n+-----------------+---+----------+\n|         L. Messi| 32|       384|\n|Cristiano Ronaldo| 34|       408|\n|        Neymar Jr| 27|       324|\n|         J. Oblak| 26|       312|\n|        E. Hazard| 28|       336|\n+-----------------+---+----------+\nonly showing top 5 rows\n\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Escenario 1\n",
    "df_fifa.withColumn('edad_meses', df_fifa.age * 12).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d972e386-9e15-44e8-bffc-69f32f03755c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+-----------------+---+\n",
       "|       short_name|age|\n",
       "+-----------------+---+\n",
       "|         L. Messi| 32|\n",
       "|Cristiano Ronaldo| 34|\n",
       "|        Neymar Jr| 27|\n",
       "|         J. Oblak| 26|\n",
       "|        E. Hazard| 28|\n",
       "+-----------------+---+\n",
       "only showing top 5 rows\n",
       "\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "+-----------------+---+\n|       short_name|age|\n+-----------------+---+\n|         L. Messi| 32|\n|Cristiano Ronaldo| 34|\n|        Neymar Jr| 27|\n|         J. Oblak| 26|\n|        E. Hazard| 28|\n+-----------------+---+\nonly showing top 5 rows\n\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Escenario 2\n",
    "df_fifa.withColumn('edad_dias', df_fifa.age * 365)\n",
    "df_fifa.drop('edad_dias')\n",
    "df_fifa.show(5)\n",
    "\n",
    "#Drop the column “edad_dias”.\n",
    "#Print the output of the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3e052d57-74d9-4144-a67d-ebca3d3b9499",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "En el escenario 2 observamos que las ventajas de Spark Lazy. Es decir, Spark se da cuenta de que la creación de edad_dias no tiene valor e ignora por completo ese paso. Y debido a esta \"pereza\", el trabajo corre más rápido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b0095f02-8889-4428-8794-d38cfbb2f72a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Observemos otro ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8ca470f5-2e35-4ab0-9476-62fefb823fcd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#1) Creamos una lista\n",
    "import numpy as np\n",
    "my_list = [i for i in range(1,10000000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "dd0f35f7-98b9-4419-8a2c-e527510d03a8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Número de particiones:  4\n",
       "Out[6]: ParallelCollectionRDD[351] at readRDDFromInputStream at PythonRDD.scala:413"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "Número de particiones:  4\nOut[6]: ParallelCollectionRDD[351] at readRDDFromInputStream at PythonRDD.scala:413",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Creamos un RDD a partir del array de datos\n",
    "rdd_data_0 = sc.parallelize(my_list,4)\n",
    "print(\"Número de particiones: \", rdd_data_0.getNumPartitions())\n",
    "rdd_data_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "96796a28-96ad-4ea2-b659-ddecbe8ecaf4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[352] at RDD at PythonRDD.scala:58\n",
       "Out[7]: b'(4) PythonRDD[352] at RDD at PythonRDD.scala:58 []\\n |  ParallelCollectionRDD[351] at readRDDFromInputStream at PythonRDD.scala:413 []'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "PythonRDD[352] at RDD at PythonRDD.scala:58\nOut[7]: b'(4) PythonRDD[352] at RDD at PythonRDD.scala:58 []\\n |  ParallelCollectionRDD[351] at readRDDFromInputStream at PythonRDD.scala:413 []'",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aplicamos una transformación básica: sumamos 5 a cada elemento del RDD\n",
    "rdd_data_1 = rdd_data_0.map(lambda x : x+5) #en este punto Spark, no ha iniciado ninguna transformación, \n",
    "                                            #solo registra una serie de transformaciones en la forma linaje RDD.\n",
    "# RDD object\n",
    "print(rdd_data_1)\n",
    "\n",
    "#debugging\n",
    "rdd_data_1.toDebugString()  #observando el linaje RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7d4d1a9e-59a3-451c-8b97-4e36b2999d8d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Observamos que PythonRDD[352] está conectado a ParallelCollectionRDD[351]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8cf11088-3709-4050-86ed-625aee4c97e2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[353] at RDD at PythonRDD.scala:58\n",
       "b'(4) PythonRDD[353] at RDD at PythonRDD.scala:58 []\\n |  ParallelCollectionRDD[351] at readRDDFromInputStream at PythonRDD.scala:413 []'\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "PythonRDD[353] at RDD at PythonRDD.scala:58\nb'(4) PythonRDD[353] at RDD at PythonRDD.scala:58 []\\n |  ParallelCollectionRDD[351] at readRDDFromInputStream at PythonRDD.scala:413 []'\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "ansi"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Una vez más sumamos valores al RDD\n",
    "rdd_data_2 = rdd_data_1.map(lambda x : x+20)\n",
    "\n",
    "# RDD Object\n",
    "print(rdd_data_2)\n",
    "\n",
    "# Conseguimos el linaje\n",
    "print(rdd_data_2.toDebugString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b656fe05-4937-49cd-9ce1-5446cc4a17ee",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Observamos que PythonRDD[353] está conectado a ParallelCollectionRDD[351].\n",
    "Podemos ver que automáticamente se ha saltado un paso redundante y agregará 25 en un solo paso en lugar de cómo lo definimos. Entonces, Spark define automáticamente la mejor ruta para realizar cualquier acción y solo realiza las transformaciones cuando es necesario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8700c5bf-0fb8-4035-9af9-d42a8a310a60",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Ventajas de la evaluación \"lazy\"\n",
    "- Reduce la complejidad: Las dos complejidades principales de cualquier operación son el tiempo y del espacio. Usando la evaluación perezosa de Apache Spark podemos superar ambos. Como no ejecutamos todas las operaciones, por lo tanto, se ahorra tiempo. Nos permite trabajar con una estructura de datos infinita. La acción se activa solo cuando se requieren los datos, reduce la sobrecarga.\n",
    "\n",
    "- Optimización de recursos: la optimización se logra a através de reducir el número de recursos a emplear.\n",
    "\n",
    "- Ahorro de cómputo e incrementa la velocidad: la evaluación perezosa juega un papel clave en el ahorro de gastos generales de cálculo. Dado que solo los valores necesarios se calculan. Ahorra el viaje entre el conductor y el grupo, por lo que acelera el proceso.\n",
    "\n",
    "\n",
    "### Ejercicio\n",
    "\n",
    "\n",
    "a) Aplica 10 funciones lambda sumando 200 (rdd_data_0.map(lambda x : x+200)) e imprime el resultado posteriormente.\n",
    "\n",
    "b) Aplica 1 función lambda sumando 2000 (rdd_data_0.map(lambda x : x+2000)) e imprime el resultado posteriormente.\n",
    "\n",
    "c) Mide el tiempo de ejecución para a) y b). Discute brevemente los resultados.\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "lazy_evaluation",
   "notebookOrigID": 3827491274431600,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
